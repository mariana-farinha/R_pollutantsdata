qqPlot(V6) #Tirando dois pontos, podemos aceitar a normalidade
qqPlot(V7) #NÃƒÂ£o apresentam normalidade
qqPlot(V10) #NÃƒÂ£o apresentam normalidade
qqPlot(V11) #NÃƒÂ£o apresentam normalidade
qqPlot(V12) #Tirando um ponto, podemos aceitar a normalidade
install.packages("car")
attach(dados)
####################################################
###########ANÃƒÂLISE EXPLORATÃƒÂ“RIA DOS DADOS###########
####################################################
dim(dados)
class(dados[,1])
class(dados[,2])
class(dados[,3])
class(dados[,4])
class(dados[,5])
class(dados[,6])
class(dados[,7])
class(dados[,8])
class(dados[,9])
class(dados[,10])
class(dados[,11])
class(dados[,12])
#Temos todas as variÃƒÂ¡veis como numÃƒÂ©ricas ou inteiras.
dados[,8] <- ifelse(dados[,8]==1, 1, 0)
dados[,8]<-as.factor(dados[,8])
class(dados[,8])
dados[,9]<-as.factor(dados[,9])
class(dados[,9])
summary(dados)
#V1            V2               V3
#Min.   :  1   Min.   : 6.700   Min.   :38.80
#1st Qu.: 29   1st Qu.: 8.340   1st Qu.:50.90
#Median : 57   Median : 9.420   Median :53.20
#Mean   : 57   Mean   : 9.648   Mean   :53.23
#3rd Qu.: 85   3rd Qu.:10.470   3rd Qu.:56.20
#Max.   :113   Max.   :19.560   Max.   :65.90
#
#V4              V5              V6
#Min.   :1.300   Min.   : 1.60   Min.   : 39.60
#1st Qu.:3.700   1st Qu.: 8.40   1st Qu.: 69.50
#Median :4.400   Median :14.10   Median : 82.30
#Mean   :4.355   Mean   :15.79   Mean   : 81.63
#3rd Qu.:5.200   3rd Qu.:20.30   3rd Qu.: 94.10
#Max.   :7.800   Max.   :60.50   Max.   :133.50
#
#V7              V8             V9
#Min.   : 29.0  0:96           1:28
#1st Qu.:106.0  1:17           2:32
#Median :186.0                 3:37
#Mean   :252.2                 4:16
#3rd Qu.:312.0
#Max.   :835.0
#
#V10             V11             V12
#Min.   : 20.0   Min.   : 14.0   Min.   : 5.70
#1st Qu.: 68.0   1st Qu.: 66.0   1st Qu.:31.40
#Median :143.0   Median :132.0   Median :42.90
#Mean   :191.4   Mean   :173.2   Mean   :43.16
#3rd Qu.:252.0   3rd Qu.:218.0   3rd Qu.:54.30
#Max.   :791.0   Max.   :656.0   Max.   :80.00
#CONCLUSÃƒÂ•ES:
#As variÃƒÂ¡veis com maior variabilidade sÃƒÂ£o V7, V10 e V11.
#As variÃƒÂ¡veis com menor variabilidade sÃƒÂ£o V2 e V4.
#As restantes variÃƒÂ¡veis tÃƒÂªm uma variabilidade intermÃƒÂ©dia.
#Separando os boxplots pelas variabilidades dos dados:
boxplot(dados[,c(7,10,11)],range=3,main="", horizontal=T)
boxplot(dados[,c(3,5,6,12)],range=3,main="", horizontal=T)
boxplot(dados[,c(2,4)],range=3,main="", horizontal=T)
#CONCLUSÃƒÂ•ES:
#As variÃƒÂ¡veis V2 e V5 apresentam outliers, dois no primeiro caso e um no segundo.
boxplot(dados[,2],horizontal=T, range=3)$out #Outliers: 19.56 e 17.94
which(V2>=17.94) #Os outliers correspondem ÃƒÂ s observaÃƒÂ§ÃƒÂµes 47 e 112.
boxplot(dados[,5],range=3, horizontal=T)$out #Outlier: 60.5
which(V5==60.5) #O outlier corresponde ÃƒÂ  observaÃƒÂ§ÃƒÂ£o 8.
#CONCLUSÃƒÂƒO: SerÃƒÂ¡ necessÃƒÂ¡rio avaliar estas mesmas observaÃƒÂ§ÃƒÂµes posteriormente de modo a analisar a sua influÃƒÂªncia nos modelos.
#REPRESENTAÃƒÂ‡ÃƒÂƒO DAS RELAÃƒÂ‡ÃƒÂ•ES ENTRE OS DADOS
library(psych)
pairs.panels(dados,ellipses=F,smooth=F) #AnÃƒÂ¡lise preliminar das relaÃƒÂ§ÃƒÂµes entre os dados
pairs(dados[-c(8,47,112),]) #AnÃƒÂ¡lise preliminar das relaÃƒÂ§ÃƒÂµes entre os dados sem outliers
corelacao<-cor(dados[,-c(8,9)])
cor.plot(corelacao,numbers=T,colors=T,show.legend=T,n.legend=10,main="CorrelaÃƒÂ§ÃƒÂµes entre as VariÃƒÂ¡veis")
cor.plot(corelacao,numbers=T,colors=T,show.legend=T,n.legend=10,main="")
#######################################################
###########DIVISÃƒÂƒO DA AMOSTRA PARA VALIDAÃƒÂ‡ÃƒÂƒO###########
#######################################################
set.seed(2014)
obs.val<-sample(dados[,1],0.10*113,replace=F) #11 observaÃƒÂ§ÃƒÂµes para validar
obs.val
dad.train<-dados[-c(obs.val),]
dad.test<-dados[c(sort(obs.val)),]
class(dad.train)
class(dad.test)
summary(dad.train)
summary(dad.test)
#A observaÃƒÂ§ÃƒÂ£o 11 faz extrapolaÃƒÂ§ÃƒÂ£o nos dados de teste, por isso, ÃƒÂ© necessÃƒÂ¡rio mudÃƒÂ¡-la
#- corresponde ÃƒÂ  nona entrada de obs.val. Temos entÃƒÂ£o que fazer uma alteraÃƒÂ§ÃƒÂ£o nas duas
#amostras usadas.
obs.valr<-obs.val[-9]
obs.valr
obs.test<-c(obs.valr,9)
dad.train<-dados[-c(obs.test),]
dad.test<-dados[c(sort(obs.test)),]
dim(dad.train)
dim(dad.test)
summary(dad.train)
dad.test
summary(dad.test)
#Temos 14 parÃƒÂ¢metros a estimar (devido ÃƒÂ s variÃƒÂ¡veis categÃƒÂ³ricas,
#uma binÃƒÂ¡ria e outra com 4 nÃƒ­veis).
102/14 #=7.2857 observaÃƒÂ§ÃƒÂµes por parÃƒÂ¢metro
boxplot(log(V2),horizontal=T,range=3) #log(V2) nÃƒÂ£o apresenta outliers
library(car)
qqPlot(log(V2)) #Temos duas observaÃƒÂ§ÃƒÂµes nÃƒÂ£o normais.
qqPlot(log(V2[-c(47,112)])) #As observaÃƒÂ§ÃƒÂµes nÃƒÂ£o normais correspondem aos outliers de V2.
dados[c(43,47,101,112),]
library(car)
qqPlot(V1) #NÃƒÂ£o apresentam normalidade
qqPlot(V2) #NÃƒÂ£o apresentam normalidade
qqPlot(V3) #Existem pontos que nÃƒÂ£o nos permitem aceitar a normalidade.
qqPlot(V4) #NÃƒÂ£o apresentam normalidade
qqPlot(V5) #NÃƒÂ£o apresentam normalidade
qqPlot(V6) #Tirando dois pontos, podemos aceitar a normalidade
qqPlot(V7) #NÃƒÂ£o apresentam normalidade
qqPlot(V10) #NÃƒÂ£o apresentam normalidade
qqPlot(V11) #NÃƒÂ£o apresentam normalidade
qqPlot(V12) #Tirando um ponto, podemos aceitar a normalidade
#################################################
######CONSTRUÃƒÂ‡ÃƒÂƒO DE VÃƒÂRIOS MODELOS LINEARES######
#################################################
#Modelo linear com todas as variÃƒÂ¡veis
m1 <- lm(dad.train$V2~.,data=dad.train)
summary(m1) #R^2=0.6565; R^2 ajustado=0.6057
anova(m1) #Testes F parcial para avaliar a influÃƒÂªncia que uma
#nova variÃƒÂ¡vel tem no modelo com todas elas.
y.pred.m1 <- predict(m1,dad.test)
summary((y.pred.m1 - dad.test$V2)^2)
summary(V2)
range(V2)[2]-range(V2)[1] #Amplitude amostral=12.86
sd(V2) #Desvio padrÃƒÂ£o=1.911456
#Logo resÃƒ­duos iguais a 5.912 sÃƒÂ£o resÃƒ­duos elevados.
#Modelo com base na anÃƒÂ¡lise de todos os subconjuntos (sem as variÃƒÂ¡veis categÃƒÂ³ricas)
library(leaps)
lr <- leaps(dad.train[,c(1,3:7,10:12)],dad.train[,2],method='r2')
plot(lr$size,lr$r2) #AtÃƒÂ© 8 (a contar com a resposta), no mÃƒÂ¡ximo.
lcp <- leaps(dad.train[,c(1,3:7,10:12)],dad.train[,2],method='Cp')
plot(lcp$size,lcp$Cp) #7 ou 8 variÃƒÂ¡veis (a contar com a resposta)
lraj <- leaps(dad.train[,c(1,3:7,10:12)],dad.train[,2],method='adjr2')
plot(lraj$size,lraj$adjr2) #AtÃƒÂ© 8 (a contar com a resposta), no mÃƒÂ¡ximo.
best.fit.cp <- lcp$which[which.min(lcp$Cp),]
best.fit.cp<-which(best.fit.cp)
best.fit.cp #3,4,5,6,7,10,11 do modelo original
best.var.cp89<-c(8,9,3,4,5,6,7,10,11) #acrescentando as variÃƒÂ¡veis categÃƒÂ³ricas
summary(dad.train[,best.var.cp89])
m.best.cp89 <- lm(dad.train$V2 ~ .,data=dad.train[,best.var.cp89])
summary(m.best.cp89) #R^2=0.6521; R^2 ajustado=0.6096
y.pred.best.cp89 <- predict(m.best.cp89,dad.test[,best.var.cp89])
summary((y.pred.best.cp89 - dad.test$V2)^2)
#Temos resÃƒ­duos ainda mais elevados, 6.437, o que, dada a variabilidade de V2
#podemos considerar muito elevados.
best.var.cp9<-c(9,3,4,5,6,7,10,11)
summary(dad.train[,best.var.cp9])
m.best.cp9 <- lm(dad.train$V2 ~ .,data=dad.train[,best.var.cp9])
summary(m.best.cp9) #R^2=0.6518; R^2 ajustado=0.6135
y.pred.best.cp9 <- predict(m.best.cp9,dad.test[,best.var.cp9])
summary((y.pred.best.cp9 - dad.test$V2)^2)
#Os resÃƒ­duos continuam a ser elevados.
best.var.cp8<-c(8,3,4,5,6,7,10,11)
summary(dad.train[,best.var.cp8])
m.best.cp8<- lm(dad.train$V2 ~ .,data=dad.train[,best.var.cp8])
summary(m.best.cp8) #R^2=0.5822; R^2 ajustado=0.5463
y.pred.best.cp8 <- predict(m.best.cp8,dad.test[,best.var.cp8])
summary((y.pred.best.cp8 - dad.test$V2)^2)
#Continuamos a ter o mesmo problema com os resÃƒ­duos.
best.var.cp<-c(3,4,5,6,7,10,11)
summary(dad.train[,best.var.cp])
m.best.cp<- lm(dad.train$V2 ~ .,data=dad.train[,best.var.cp])
summary(m.best.cp) #R^2=0.582; R^2 ajustado=0.5509
y.pred.best.cp <- predict(m.best.cp,dad.test[,best.var.cp])
summary((y.pred.best.cp - dad.test$V2)^2)
#Continuamos a ter o mesmo problema com os resÃƒ­duos.
library(MASS)
m.new.best.cp<-lm(dad.train$V2 ~ V3 + V4 + V5 + V6 + V7 + V10 + V11,data=dad.train)
m.new.best.cp
addterm(m.new.best.cp, scope =m.full, test="F" )
m.new1.best.cp<-update(m.new.best.cp, .~. + V9) #V9 tem valor p mais baixo
dropterm(m.new1.best.cp,test="F") #Temos de retirar a V5.
m.new2.best.cp<-update(m.new1.best.cp, .~. -V5)
dropterm(m.new2.best.cp,test="F") #Temos de retirar a V7.
m.new3.best.cp<-update(m.new2.best.cp, .~. -V7)
dropterm(m.new3.best.cp,test="F") #Temos de retirar a V6.
m.new4.best.cp<-update(m.new3.best.cp, .~. -V6)
dropterm(m.new4.best.cp,test="F") #NÃƒÂ£o temos nenhuma para retirar.
addterm(m.new4.best.cp,scope=m.full,test="F") #NÃƒÂ£o temos mais nenhuma para acrescentar.
#Obtemos o mesmo modelo que serÃƒÂ¡ obtido no cÃƒÂ³digo a seguir, sem as variÃƒÂ¡veis V6 e V7.
best.fit.raj<-lraj$which[which.max(lraj$adjr2),]
best.fit.raj<-which(best.fit.raj)
best.fit.raj #Obtemos as mesmas variÃƒÂ¡veis do que quando usamos o mÃƒÂ©todo Cp.
#Modelo com base no Step-by-step (aqui jÃƒÂ¡ podemos usar as variÃƒÂ¡veis categÃƒÂ³ricas)
#Como V4, pelos testes t, na regressÃƒÂ£o com todas as variÃƒÂ¡veis ÃƒÂ© muito significativa,
#entÃƒÂ£o coloquemos como modelo base o modelo apenas constituÃƒ­do por esta variÃƒÂ¡vel e
#como modelo superior o modelo com todas as variÃƒÂ¡veis.
m.base4 <-lm(dad.train$V2~V4,data=dad.train)
summary(m.base4) #0.3095; 0.3026
m.full<- lm(dad.train$V2~.,data=dad.train)
summary(m.full)
model.sbs4<-step(m.base4,scope =list(upper=m.full,lower=~1), direction = "both", trace=FALSE)
summary(model.sbs4) #R^2=0.6487; r^2 ajustado= 0.6144
model.sbs4f<-step(m.base4,scope =list(upper=m.full,lower=~1), direction = "forward", trace=FALSE)
summary(model.sbs4f) #O mesmo que o anterior
model.sbs4b<-step(m.full,direction = "backward", trace=FALSE)
summary(model.sbs4b) #Novamente o mesmo
#Modelo step-by-step manualmente
library(MASS)
m.null<- lm(dad.train$V2~ 1,data=dad.train)
summary(m.null)
m.full<- lm(dad.train$V2~.,data=dad.train)
summary(m.full)
addterm(m.null, scope =m.full, test="F" )
m.new<-update(m.null, .~. + V4) #V4 tem valor de F mais elevado acima de 4
addterm(m.new, scope =m.full, test="F" )
m.new1<-update(m.new, .~. + V9) #V9 tem valor p mais baixo
dropterm(m.new1,test="F") #Todos tÃƒÂªm valores de F acima de 3.9, logo nÃƒÂ£o eliminamos nenhum
addterm(m.new1,scope=m.full,test="F")
m.new2<-update(m.new1,.~. + V10) #V10 tem valor de F mais elevado acima de 4
dropterm(m.new2,test="F") #Todos tÃƒÂªm valores de F acima de 3.9, logo nÃƒÂ£o eliminamos nenhum
addterm(m.new2,scope=m.full,test="F")
m.new3<-update(m.new2, .~. +V11) #V11 tem valor de F mais elevado acima de 4
dropterm(m.new3,test="F") #Todos tÃƒÂªm valores de F acima de 3.9, logo nÃƒÂ£o eliminamos nenhum
addterm(m.new3,scope=m.full,test="F")
m.new4<-update(m.new3, .~. +V3) #V3 tem valor de F mais elevado (apesar de ser inferior a 4)
dropterm(m.new4,test="F") #Todos tÃƒÂªm valores de p-value abaixo de 0.1, logo nÃƒÂ£o eliminamos nenhum
addterm(m.new4,scope=m.full,test="F")
#??????????????????? PODEMOS ENTRAR COM V9, OU TEMOS QUE SUBDIVIDIR? EM CASO DE SUBDIVISÃƒÂƒO,
#AO ENTRAR COM V91 NÃƒÂƒO ÃƒÂ‰ NECESSÃƒÂRIO ENTRAR COM V92 E V93?????????????????????
model.sbs4 #a diferenÃƒÂ§a estÃƒÂ¡ em V6 e V7, logo precisamos de verificar se V6 e V7 nÃƒÂ£o tem o
#parÃƒÂ¢metro associado nulo.
#R^2=0.6487; R^2 ajustado=0.6144
#ResÃƒ­duos elevados: -1.9656 atÃƒÂ© 6.1084 (apesar de o 3Ã‚Âºquantil ser 0.5908)
summary(model.sbs4) #Podemos verificar que V6 e V7 podem ser consideradas com os beta nulos,
#ou seja, V6 e V7 nÃƒÂ£o entram no modelo.
anova(model.sbs4)
summary(m.new4)
#R^2=0.6317, R^2 ajustado=0.6042
#ResÃƒ­duos elevados: -2.2020 atÃƒÂ© 6.2945 (apesar de o 1Ã‚Âº quantil ser -0.7549 e o 3Ã‚Âºquantil ser
#0.7139).
anova(m.new4)
model.sbs<-model.sbs4
class(model.sbs$coefficients)
length(model.sbs$coefficients)
model.sbs$coefficients[9]<-0
model.sbs$coefficients[10]<-0
model.sbs$coefficients
anova(model.sbs)
summary(model.sbs)
y.pred.model.sbs4<-predict(model.sbs4,dad.test)
summary((y.pred.model.sbs4-dad.test$V2)^2)
#Existe um erro da ordem de grandeza de 6.187.
y.pred.model.sbs <- predict(model.sbs,dad.test)
summary((y.pred.model.sbs - dad.test$V2)^2)
#Considerando os betas de V6 e V7 nulos,
#existe um erro da ordem de grandeza de 14.67.
y.pred.m.new4<-predict(m.new4,dad.test)
summary((y.pred.m.new4-dad.test$V2)^2)
#Existe um erro da ordem de grandeza de 8.13.
summary(m.new4$residuals)
Sweave("aml.Snw")
cube <- function(x,n) {}
cube <- function(x,n) {
x^3
}
cube(4)
library(datasets)
data(iris)
?iris
iris
iris[Species == virginica]
iris[Species]
iris[species]
iris[1]
iris[Sepal.Length]
iris[[Sepal.Length]]
iris[["Sepal.Length"]]
iris[iris$Species == virginica]
iris[iris$Species == 'virginica']
s <- iris$Species
s[s == 'virginica']
s == 'virginica'
iris$Sepal.Length[s=='virginica']
mean(iris$Sepal.Length[s=='virginica'])
?colMeans
colMeans(iris)
?apply
?rm
rm(s)
library(datasets)
data(mtcars)
?mtcars
?tapply
?with
?tapply
?sapply
head(mtcars)
?mean
?tapply
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mpg, cyl, mean)
?with
with(mtcars, tapply(mtcars$mpg, mtcars$cyl, mean))
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(hp, cyl, mean))
a<-with(mtcars, tapply(hp, cyl, mean))
a$4
a[[1]]
a[[4]]-a[[8]]
a[[1]]-a[[3]]
ls()
debug(ls)
ls()
function (name, pos = -1L, envir = as.environment(pos), all.names = FALSE,
pattern, sorted = TRUE)
{
if (!missing(name)) {
pos <- tryCatch(name, error = function(e) e)
if (inherits(pos, "error")) {
name <- substitute(name)
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
if (!is.character(name))
name <- deparse(name)
exit
Q()
q
print Q
q
q
ls()
sorted
function (name, pos = -1L, envir = as.environment(pos), all.names = FALSE,
q
clear
ls()
swirl()
Swirl()
library(Swirl)
library(swirl)
swirl()
5+7
x <- 5+7
x
y<-x-3
y
z <- c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div <- z/my_sqrt
my_div
c(1,2,3,4) + c(0,10)
c(1,2,3,4) + c(0,10,100)
quit
quit()
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("complete.R")
complete("specdata",1)
complete("specdata", c(2, 4, 8, 10, 12))
id <- c(2, 4, 8, 10, 12)
1:length(id)
for(i in 1:length(id)){print(i)}
source("complete.R")
complete("specdata", c(2, 4, 8, 10, 12))
id <- c(2, 4, 8, 10, 12)
c<-id[2]
source("complete.R")
complete("specdata", c(2, 4, 8, 10, 12))
source("complete.R")
complete("specdata", c(2, 4, 8, 10, 12))
complete("specdata", 30:25)
complete("specdata", 3)
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 70:72)
pollutantmean("specdata", "nitrate", 23)
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("pollutantmean.R")
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "nitrate", 23)
d <- 3
cbind(d,5)
rbind(d,5)
append(c(1,4),d)
d<-c()
append(d,1)
d
is.null(d)
source("corr.R")
cr <- corr("specdata", 150)
head(cr)
source("corr.R")
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
cr <- corr("specdata", 150)
head(cr)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
cr <- corr("specdata", 150)
head(cr)
cr <- corr("specdata", 150)
head(cr)
source("corr.R")
cr <- corr("specdata", 150)
head(cr)
cr
source("corr.R")
cr <- corr("specdata", 150)
head(cr)
debug(corr)
cr <- corr("specdata", 150)
total_complete > 150
cor(current_csv['nitrate'], current_csv['sulfate'])
current_csv['nitrate']
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
c<-corr("specdata", 150)
source("corr.R")
c<-corr("specdata", 150)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
c<-corr("specdata", 150)
debug(corr)
c<-corr("specdata", 150)
a<- complete.cases(current_csv)
b<-current_csv[a]
b<-current_csv[[a]]
sum(a)
b<-current_csv[a,]
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
undebug(corr)
undebug(corr)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
undebug(corr)
dir()
source("corr.R")
c<-corr("specdata", 150)
debug(corr)
c<-corr("specdata", 150)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
c<-corr("specdata", 150)
c
debug(corr)
c<-corr("specdata", 150)
c<-complete.cases(current_csv)
a<-current_csv['nitrate']
cor(current_csv['nitrate'], current_csv['sulfate'])
as.numeric(cor(current_csv['nitrate'], current_csv['sulfate']))
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
undebug(corr)
c<-corr("specdata", 150)
debug(corr)
c<-corr("specdata", 150)
undebug(corr)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
c<-corr("specdata", 150)
debug(corr)
c<-corr("specdata", 150)
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
source("corr.R")
c<-corr("specdata", 150)
head(c)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
2
submit()
submit()
submit()
submit()
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
submit()
setwd("C:/Users/fernando farinha/Desktop/rprog-data-specdata")
submit()
submit()
submit()
submit()
submit()
submit()
submit()
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
corr("specdata", 14000)
c<-corr("specdata", 14000)
c
as.numeric(c)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
submit()
